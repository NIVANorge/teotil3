{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40d7f8-39c2-4e50-b143-d243882a9536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Run this and then restart the kernel at the start of each session to install\n",
    "# # 'teotil3' in development mode\n",
    "# !pip install -e /home/jovyan/projects/teotil3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99215781-f77e-4b3b-8342-41ac7482f061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import teotil3 as teo\n",
    "from sqlalchemy import text\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d8e444-aba9-4f4d-b4c5-700632270745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  ········\n",
      "Password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "eng = nivapy.da.connect_postgis(admin=True)\n",
    "# eng = nivapy.da.connect_postgis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01323f7-1940-4710-a238-4bd3ab1d4d9e",
   "metadata": {},
   "source": [
    "# TEOTIL3: Upload annual data\n",
    "\n",
    "First run notebooks 01 to 07 to clean and prepare the raw annual data. **This notebook will upload the processed annual data for the specified time period** (removing any older data previously uploaded for the same period). It is usually a good idea to **upload an entire cleaned dataset** for the period from 2013 to the final year of interest, as this ensures that TEOTIL3 remains up-to-date with changes in primary data sources, like Miljødirektoratet's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efab367e-ad4f-4025-8ee5-fa451687f799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st_yr, end_yr = 2013, 2023\n",
    "years = range(st_yr, end_yr + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028a849b-b340-4768-bf5b-80077a356729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete data already in the database for these years\n",
    "with eng.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\n",
    "            \"\"\"DELETE FROM teotil3.point_source_values\n",
    "               WHERE year >= :st_yr\n",
    "               AND year <= :end_yr\n",
    "        \"\"\"\n",
    "        )\n",
    "        conn.execute(sql, {\"st_yr\": st_yr, \"end_yr\": end_yr})\n",
    "\n",
    "        sql = text(\n",
    "            \"\"\"DELETE FROM teotil3.point_source_locations\n",
    "               WHERE year >= :st_yr\n",
    "               AND year <= :end_yr\n",
    "        \"\"\"\n",
    "        )\n",
    "        conn.execute(sql, {\"st_yr\": st_yr, \"end_yr\": end_yr})\n",
    "\n",
    "        sql = text(\n",
    "            \"\"\"DELETE FROM teotil3.spredt_inputs\n",
    "               WHERE year >= :st_yr\n",
    "               AND year <= :end_yr\n",
    "        \"\"\"\n",
    "        )\n",
    "        conn.execute(sql, {\"st_yr\": st_yr, \"end_yr\": end_yr})\n",
    "\n",
    "        sql = text(\n",
    "            \"\"\"DELETE FROM teotil3.agri_inputs\n",
    "               WHERE year >= :st_yr\n",
    "               AND year <= :end_yr\n",
    "        \"\"\"\n",
    "        )\n",
    "        conn.execute(sql, {\"st_yr\": st_yr, \"end_yr\": end_yr})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd2e99-0ad7-4707-aa57-b5dd7b0d5830",
   "metadata": {},
   "source": [
    "## 1. Large wastewater treatment plants and industry\n",
    "\n",
    "This step processes the raw data from three files:\n",
    "\n",
    " * `large_wastewater_{year}_raw.xlsx`\n",
    " * `metals_{year}_raw.xlsx`\n",
    " * `industry_{year}_raw.xlsx`\n",
    "\n",
    "Files for each year are hosted on `shared`:\n",
    "\n",
    "    shared/common/teotil3/point_data/{year}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f0bebd-4201-4613-9480-7a1b6877349a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2013 #################\n",
      "# 2014 #################\n",
      "# 2015 #################\n",
      "# 2016 #################\n",
      "# 2017 #################\n",
      "# 2018 #################\n",
      "# 2019 #################\n",
      "1 locations do not have outlet co-ordinates in this year's data.\n",
      "         site_id                                      name\n",
      "90  2311.0001.01  Hav Line - Slakteskipet Norwegian Gannet\n",
      "# 2020 #################\n",
      "1 locations do not have outlet co-ordinates in this year's data.\n",
      "         site_id                                      name\n",
      "83  2311.0001.01  Hav Line - Slakteskipet Norwegian Gannet\n",
      "# 2021 #################\n",
      "1 locations do not have outlet co-ordinates in this year's data.\n",
      "         site_id                                      name\n",
      "87  2311.0001.01  Hav Line - Slakteskipet Norwegian Gannet\n",
      "# 2022 #################\n",
      "1 locations do not have outlet co-ordinates in this year's data.\n",
      "         site_id                                      name\n",
      "90  2311.0001.01  Hav Line - Slakteskipet Norwegian Gannet\n",
      "# 2023 #################\n",
      "1 locations do not have outlet co-ordinates in this year's data.\n",
      "         site_id                                      name\n",
      "89  2311.0001.01  Hav Line - Slakteskipet Norwegian Gannet\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(\"#\", year, \"#################\")\n",
    "    data_fold = f\"/home/jovyan/shared/common/teotil3/point_data/{year}\"\n",
    "    loc_gdf, df = teo.preprocessing.read_large_wastewater_and_industry_data(\n",
    "        data_fold, year, eng\n",
    "    )\n",
    "\n",
    "    # # Add new sites to the database\n",
    "    # loc_gdf.to_postgis(\n",
    "    #     \"point_source_locations\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )\n",
    "\n",
    "    # # Add values to database\n",
    "    # df.to_sql(\n",
    "    #     \"point_source_values\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580c256-99a2-4f90-a69c-cac2e14e053e",
   "metadata": {},
   "source": [
    "## 2. Small wastewater treatment plants\n",
    "\n",
    "Process files named `small_wastewater_{year}.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b93574-aed2-4a57-afdf-118bfd883e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2013 #################\n",
      "# 2014 #################\n",
      "# 2015 #################\n",
      "# 2016 #################\n",
      "# 2017 #################\n",
      "# 2018 #################\n",
      "# 2019 #################\n",
      "# 2020 #################\n",
      "# 2021 #################\n",
      "# 2022 #################\n",
      "# 2023 #################\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(\"#\", year, \"#################\")\n",
    "    xl_path = f\"/home/jovyan/shared/common/teotil3/point_data/{year}/small_wastewater_{year}_raw.xlsx\"\n",
    "    df = teo.preprocessing.read_raw_small_wastewater_data(xl_path, \"Sheet1\", year, eng)\n",
    "\n",
    "    # # Add to database\n",
    "    # df.to_sql(\n",
    "    #     \"spredt_inputs\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc74e4-e47c-4716-969a-205588175f2d",
   "metadata": {},
   "source": [
    "## 3. Aquaculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2901aaca-2097-4fc3-87a9-4920c33ac070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2013 #################\n",
      "The total annual copper lost to water from aquaculture is 923.1 tonnes.\n",
      "# 2014 #################\n",
      "The total annual copper lost to water from aquaculture is 960.5 tonnes.\n",
      "# 2015 #################\n",
      "The total annual copper lost to water from aquaculture is 980.9 tonnes.\n",
      "# 2016 #################\n",
      "The total annual copper lost to water from aquaculture is 1134.8 tonnes.\n",
      "# 2017 #################\n",
      "The total annual copper lost to water from aquaculture is 1217.2 tonnes.\n",
      "# 2018 #################\n",
      "The total annual copper lost to water from aquaculture is 1382.1 tonnes.\n",
      "# 2019 #################\n",
      "The total annual copper lost to water from aquaculture is 1443.3 tonnes.\n",
      "# 2020 #################\n",
      "The total annual copper lost to water from aquaculture is 1308.1 tonnes.\n",
      "# 2021 #################\n",
      "The total annual copper lost to water from aquaculture is 932.4 tonnes.\n",
      "# 2022 #################\n",
      "The total annual copper lost to water from aquaculture is 374.0 tonnes.\n",
      "# 2023 #################\n",
      "The total annual copper lost to water from aquaculture is 260.1 tonnes.\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(\"#\", year, \"#################\")\n",
    "    xl_path = f\"/home/jovyan/shared/common/teotil3/point_data/{year}/fiske_oppdret_{year}_raw.xlsx\"\n",
    "    cu_tonnes = teo.preprocessing.get_annual_copper_usage_aquaculture(year)\n",
    "    loc_gdf, df = teo.preprocessing.read_raw_aquaculture_data(\n",
    "        xl_path,\n",
    "        f\"fiskeoppdrett_{year}\",\n",
    "        year,\n",
    "    )\n",
    "    df = teo.preprocessing.estimate_aquaculture_nutrient_inputs(\n",
    "        df, year, eng, cu_tonnes=cu_tonnes, species_ids=[71401, 71101]\n",
    "    )\n",
    "\n",
    "    # # Add new sites to the database\n",
    "    # loc_gdf.to_postgis(\n",
    "    #     \"point_source_locations\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )\n",
    "\n",
    "    # # Add values to database\n",
    "    # df.to_sql(\n",
    "    #     \"point_source_values\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca0b73-0e87-483c-ad56-6b22701f9bce",
   "metadata": {},
   "source": [
    "## 4. Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7cd361-c802-4c78-9f7f-14093822eef8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2013 #################\n",
      "# 2014 #################\n",
      "# 2015 #################\n",
      "# 2016 #################\n",
      "# 2017 #################\n",
      "# 2018 #################\n",
      "# 2019 #################\n",
      "# 2020 #################\n",
      "# 2021 #################\n",
      "# 2022 #################\n",
      "# 2023 #################\n"
     ]
    }
   ],
   "source": [
    "# Version of agri data to use\n",
    "agri_version = \"20241122\"\n",
    "\n",
    "# Process agricultural data\n",
    "agri_fold = r\"/home/jovyan/shared/common/teotil3/agri_data\"\n",
    "data_fold = os.path.join(agri_fold, f\"agri_data_v{agri_version}\")\n",
    "for year in years:\n",
    "    print(\"#\", year, \"#################\")\n",
    "\n",
    "    # Read NIBIO data\n",
    "    df = teo.preprocessing.read_raw_agri_data(year, data_fold)\n",
    "\n",
    "    # # Add values to database\n",
    "    # df.to_sql(\n",
    "    #     \"agri_inputs\",\n",
    "    #     con=eng,\n",
    "    #     schema=\"teotil3\",\n",
    "    #     if_exists=\"append\",\n",
    "    #     index=False,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237d5cb-b981-4622-a39c-7acedf4b311f",
   "metadata": {},
   "source": [
    "## 5. HBV modelled discharge from NVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92c028-c6e9-4598-887a-a97d060106a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Period of data to upload (i.e. final year in dataset; the data_delivery_year\n",
    "# is final_year + 1)\n",
    "final_year = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b289095-479a-477a-95c0-6c846d95f115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Folder containing modelled data\n",
    "# data_fold = r\"/home/jovyan/shared/common/teotil3/nve_hbv_data\"\n",
    "\n",
    "# df_list = []\n",
    "# search_path = os.path.join(data_fold, f\"RID_{final_year}\", \"hbv_*.var\")\n",
    "# flist = glob.glob(search_path)\n",
    "\n",
    "# # Get number of days between 1990 and year of interest\n",
    "# days = len(pd.date_range(start=\"1990-01-01\", end=\"%s-12-31\" % final_year, freq=\"D\"))\n",
    "\n",
    "# for fpath in flist:\n",
    "#     name = os.path.split(fpath)[1]\n",
    "#     vassom = name.split(\"_\")[1][-7:-4]\n",
    "\n",
    "#     df = pd.read_csv(\n",
    "#         fpath, delim_whitespace=True, header=None, names=[\"date\", \"flow_m3/s\"]\n",
    "#     )\n",
    "#     df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d/1200\")\n",
    "#     df[\"vassom\"] = vassom\n",
    "#     df[\"data_supply_year\"] = final_year + 1\n",
    "#     df = df[[\"data_supply_year\", \"vassom\", \"date\", \"flow_m3/s\"]]\n",
    "\n",
    "#     # Check st, end and length\n",
    "#     assert df[\"date\"].iloc[0] == pd.Timestamp(\n",
    "#         \"1990-01-01\"\n",
    "#     ), \"Series does not start on 01/01/1990.\"\n",
    "#     assert df[\"date\"].iloc[-1] == pd.Timestamp(\"%s-12-31\" % final_year), (\n",
    "#         \"Series does not end on 31/12/%s.\" % year\n",
    "#     )\n",
    "#     assert len(df) == days, \"Unexpected length for new series.\"\n",
    "\n",
    "#     df_list.append(df)\n",
    "\n",
    "# df = pd.concat(df_list, axis=\"rows\")\n",
    "# assert df.duplicated([\"data_supply_year\", \"vassom\", \"date\"], keep=False).sum() == 0\n",
    "\n",
    "# print(f\"{len(df)/1e6:.1f} million rows to insert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0c360-3476-439d-ac31-98942901854f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # The databasse can't cope with writing millions of rows directly from pandas\n",
    "# # Instead, manually split the dataframe into chunks and write one\n",
    "# # at a time\n",
    "# chunk_size = 100000\n",
    "\n",
    "# table_name = \"nve_hbv_discharge\"\n",
    "\n",
    "# # Write chunks in append mode\n",
    "# chunks = [df[i : i + chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "# for chunk in tqdm(chunks):\n",
    "#     chunk.to_sql(\n",
    "#         table_name,\n",
    "#         eng,\n",
    "#         schema=\"teotil3\",\n",
    "#         index=False,\n",
    "#         if_exists=\"append\",\n",
    "#         method=\"multi\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af53ac0-3982-4c53-9e42-605c4df3a72d",
   "metadata": {},
   "source": [
    "## 6. Checking\n",
    "\n",
    "### 6.1. Check point source locations\n",
    "\n",
    "The code below plots the point source locations for a specific year. The map provides a useful way to identify obvious co-ordinate errors.\n",
    "\n",
    "**It is a good idea to check one year at a time, because errors often overlap**.\n",
    "\n",
    "See also notebook `T2-12b_check_outlet_locs.ipynb`, which checks the outlet co-ordinates provided by MDir during autumn 2023. This notebook identifies several issues with the industry and wastewater data in MDir's databases. These issues have been sent to Torstein for checking and some of them have been corrected, but not all. Once all issues are fixed, a complete new set of site and outlet co-ordinates should be requested and the database updated. See the issue [here](https://github.com/NIVANorge/teotil3/issues/27) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264dd86-b93f-4dc5-a3b2-23e622560647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Year to plot\n",
    "year = 2023\n",
    "teo.vis.point_sources_map(year, eng, loc_type=\"outlet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

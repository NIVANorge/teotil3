{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719bdca-4007-44f2-9c7c-d5dabca47678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Run this and then restart the kernel at the start of each session to install\n",
    "# # 'teotil3' in development mode\n",
    "# !pip install -e /home/jovyan/projects/teotil3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274be11-dfa6-4110-9148-481d083c065f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pprint as pp\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import teotil3 as teo\n",
    "from lmfit import Parameters, fit_report, minimize\n",
    "from shapely.geometry import Point\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b622260-a04f-4eaf-a59d-e047c3882806",
   "metadata": {},
   "source": [
    "# Task 2.15: Testing, documentation and reporting\n",
    "\n",
    "## Part D: Calibrate retention\n",
    "\n",
    "The notebook for [Task 2.5a](https://nbviewer.org/github/NIVANorge/teotil3/blob/main/notebooks/development/T2-5a_est_vollenweider_params_from_data.ipynb) used literature values to build Vollenweider-style retention models for the parameters included in TEOTIL3. The notebook for [Task 2.15b](https://nbviewer.org/github/NIVANorge/teotil3/blob/main/notebooks/development/T2-15b_compare_measured_fluxes.ipynb) then compared simulated fluxes from the new model to those measured by monitoring programmes.\n",
    "\n",
    "Without any adjustment or calibration, the model performs reasonably well for most parameters. The plots below give an indication of the **initial uncalibrated performance** (where the panel on the right shows the same data with log-axes; note that R2 values apply to the unlogged data).\n",
    "\n",
    " * For all parameters, the model output shows an obvious positive correlation with observations.\n",
    "\n",
    " * **For nitrogen**, DIN is simulated well, although the log-log plot shows a slight tendency to over-predict DIN fluxes in most catchments. Modelled TON fluxes are also consistently too high, suggesting that retention of TON is probably too low.\n",
    "   \n",
    " * **For phosphorus**, TPP is over-predicted, while TDP is under-predicted. The bias is not always consistent, however, with the log-log plots suggesting that TDP, in particular, is over-predicted in small catchments and under-predicted in large ones. The lack of interannual variability captured in the TDP series implies that retention is probably too high for this parameter, while for TPP it is possible that retention is a little too low.\n",
    "\n",
    " * **TOC** is consistently under-predicted, suggesting that retention may be too high.\n",
    "\n",
    " * **SS** is substantially under-predicted and performance is in general much worse than for the other parameters.\n",
    "\n",
    "![Uncalibrated performance](../../images/uncalibrated_performance.png)\n",
    "\n",
    "This notebook explores calibrating the retention \"hyperparameters\" (i.e. the parameters of the Vollenweider models) in order to correct clear biases and achieve a better fit to the observed data. This must be done carefully, however, to avoid \"overfitting\" - a situation where a model is adjusted to fit a particular calibration dataset, but does then not generalise well to new data.\n",
    "\n",
    "In order to avoid overfitting, parameter estimates in the final retention models have been adjusted conservatively i.e. the calibrated values are not used directly, but are instead used to guide adjustment within the range of uncertainty identified by the original statistical modelling (Task 2.5a). The final model will then be further evaluated in several case study catchments to ensure results are plausible when evaluated against independent data.\n",
    "\n",
    "## 1. Calibration code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac46f4-b0cf-43cd-bc7b-618fecee598f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_input(model_pars, voll_dict, params):\n",
    "    \"\"\"Check user input is valid.\"\"\"\n",
    "    for model_par in model_pars:\n",
    "        if model_par not in voll_dict:\n",
    "            raise KeyError(f\"Model parameter '{model_par}' not in 'voll_dict'.\")\n",
    "\n",
    "    for par in params.keys():\n",
    "        model_par, calib_par = par.split(\"_\")\n",
    "        if model_par not in voll_dict:\n",
    "            raise KeyError(f\"Model parameter '{model_par}' not in 'voll_dict'.\")\n",
    "        if calib_par not in voll_dict[model_par]:\n",
    "            raise KeyError(\n",
    "                f\"Calibration parameter '{calib_par}' not in 'voll_dict[{model_par}]'.\"\n",
    "            )\n",
    "\n",
    "\n",
    "def read_observed(model_pars):\n",
    "    \"\"\"Read observed fluxes.\"\"\"\n",
    "    obs_csv = os.path.join(eval_fold, \"rid_vannmiljo_obs_data_aggregated.csv\")\n",
    "    obs_df = pd.read_csv(obs_csv)\n",
    "    obs_df[obs_df == 0] = np.nan\n",
    "    obs_df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "    # Get just pars of interest\n",
    "    cols = [f\"{par.upper()}_tonnes\" for par in model_pars]\n",
    "    obs_df = obs_df[[\"station_id\", \"regine\", \"year\"] + cols]\n",
    "\n",
    "    # Convert to long\n",
    "    obs_df = obs_df.melt(\n",
    "        id_vars=[\"station_id\", \"regine\", \"year\"], value_name=\"observed\"\n",
    "    )\n",
    "\n",
    "    return obs_df\n",
    "\n",
    "\n",
    "def remove_prefix(text, prefix):\n",
    "    \"\"\"Remove 'prefix' from 'text'.\"\"\"\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix) :]\n",
    "    return text\n",
    "\n",
    "\n",
    "def is_kystfelt(code):\n",
    "    \"\"\"Return 1 if regine is a kystfelt (numeric code after decimal), otherwise zero.\"\"\"\n",
    "    try:\n",
    "        int(code.split(\".\")[1])\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def run_model(params, st_yr, end_yr, model_pars, voll_dict, dtm_res):\n",
    "    \"\"\"Run the model from 'st_yr' to 'end_yr' for the parameters in 'model_pars'. Retention\n",
    "    parameters for the Vollenweider models are taken from 'params' and the form of the models\n",
    "    is defined in 'voll_dict'.\n",
    "    \"\"\"\n",
    "    # Get relevant observed data\n",
    "    obs_df = read_observed(model_pars)\n",
    "    obs_df = obs_df.query(\"@st_yr <= year <= @end_yr\")\n",
    "\n",
    "    # Run TEOTIL3\n",
    "    years = range(st_yr, end_yr + 1)\n",
    "    df_list = []\n",
    "    for year in years:\n",
    "        csv_path = os.path.join(\n",
    "            csv_fold,\n",
    "            f\"teotil3_input_data_nve{nve_data_year}_{year}.csv\",\n",
    "        )\n",
    "        in_df = pd.read_csv(csv_path)\n",
    "        in_df.columns = in_df.columns.str.replace(\"-\", \"\")\n",
    "\n",
    "        # Reduce number of columns for speed\n",
    "        cols = [\n",
    "            col for col in in_df.columns if any(f\"_{par}\" in col for par in model_pars)\n",
    "        ]\n",
    "        in_df = in_df[\n",
    "            [\"regine\", \"regine_down\", \"a_cat_land_km2\", \"runoff_mm/yr\", \"q_cat_m3/s\"]\n",
    "            + cols\n",
    "        ]\n",
    "\n",
    "        # Update retention estimates based on new parameters\n",
    "        for par in model_pars:\n",
    "            del in_df[f\"trans_{par}\"]\n",
    "\n",
    "        calib_dict = copy.deepcopy(voll_dict)\n",
    "        for par_name, par in params.items():\n",
    "            model_par, calib_par = par_name.split(\"_\")\n",
    "            calib_dict[model_par][calib_par] = par.value\n",
    "\n",
    "        ret_df = teo.preprocessing.assign_regine_retention(\n",
    "            reg_df, regine_col=\"regine\", dtm_res=dtm_res, voll_dict=calib_dict\n",
    "        )\n",
    "        trans_cols = [col for col in ret_df.columns if col.startswith(\"trans_\")]\n",
    "        ret_df = ret_df[[\"regine\"] + trans_cols]\n",
    "\n",
    "        # Set transmission = 1 for kystfelt\n",
    "        mask = ret_df[\"regine\"].apply(is_kystfelt)\n",
    "        ret_df.loc[mask, trans_cols] = 1\n",
    "\n",
    "        in_df = pd.merge(in_df, ret_df, how=\"left\", on=\"regine\")\n",
    "        for col in trans_cols:\n",
    "            in_df[col].fillna(1, inplace=True)\n",
    "\n",
    "        # Run TEOTIL\n",
    "        g = teo.model.run_model(\n",
    "            in_df,\n",
    "            id_col=\"regine\",\n",
    "            next_down_col=\"regine_down\",\n",
    "            totals_from_subfracs=True,\n",
    "        )\n",
    "        res_df = teo.model.model_to_dataframe(\n",
    "            g, id_col=\"regine\", next_down_col=\"regine_down\"\n",
    "        )\n",
    "        res_df[\"year\"] = year\n",
    "        df_list.append(res_df)\n",
    "    mod_df = pd.concat(df_list, axis=\"rows\")\n",
    "\n",
    "    # Reshape\n",
    "    cols = [col for col in mod_df.columns if col.startswith(\"accum_\")]\n",
    "    mod_df = mod_df[[\"regine\", \"year\"] + cols].copy()\n",
    "    cols = [remove_prefix(col, \"accum_\") for col in cols]\n",
    "    mod_df.columns = [\"regine\", \"year\"] + cols\n",
    "    for par in model_pars:\n",
    "        cols = [col for col in mod_df.columns if f\"_{par}_\" in col]\n",
    "        mod_df[f\"{par.upper()}_tonnes\"] = mod_df[cols].sum(axis=\"columns\") / 1000\n",
    "    cols = [f\"{par.upper()}_tonnes\" for par in model_pars]\n",
    "    mod_df = mod_df[[\"regine\", \"year\"] + cols]\n",
    "\n",
    "    # Convert to long\n",
    "    mod_df = mod_df.melt(id_vars=[\"regine\", \"year\"], value_name=\"modelled\")\n",
    "\n",
    "    # Join\n",
    "    res_df = pd.merge(obs_df, mod_df, how=\"left\", on=[\"regine\", \"year\", \"variable\"])\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def residual(params, st_yr, end_yr, model_pars, voll_dict, dtm_res):\n",
    "    \"\"\"Function to minimise.\"\"\"\n",
    "    res_df = run_model(params, st_yr, end_yr, model_pars, voll_dict, dtm_res)\n",
    "\n",
    "    residual = res_df[\"observed\"] - res_df[\"modelled\"]\n",
    "\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72266b7b-f6c9-4c5d-9927-a5d605d386df",
   "metadata": {},
   "source": [
    "## 2. Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13d7fd-63fd-4a12-bc04-707a98b4d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic options\n",
    "nve_data_year = 2023\n",
    "st_yr, end_yr = 2013, 2022\n",
    "dtm_res = 10\n",
    "\n",
    "# File paths\n",
    "csv_fold = r\"/home/jovyan/shared/common/teotil3/annual_input_data\"\n",
    "eval_fold = r\"/home/jovyan/shared/common/teotil3/evaluation\"\n",
    "gpkg_fold = r\"/home/jovyan/shared/common/teotil3/core_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa969b51-9a73-4598-adc0-4d11f9388867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tidied regine data\n",
    "teo_gpkg = os.path.join(gpkg_fold, \"tidied\", \"teotil3_data.gpkg\")\n",
    "reg_df = gpd.read_file(teo_gpkg, layer=\"regines\", driver=\"GPKG\")[[\"regine\"]]\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d83718-03ef-4139-aec9-97cf605bde26",
   "metadata": {},
   "source": [
    "## 3. Calibrate\n",
    "\n",
    "The code in this section can be used to calibrate any of the parameters of interest. Uncomment the block for the desired parameter and run the notebook. Results can be found in the subfolder `calibration`.\n",
    "\n",
    "### 3.1. SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6bf7f8-830e-4d83-a9f4-4c3176380e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define parameters of interest and default Vollenweider models (based on original literature data)\n",
    "# model_pars = [\"ss\"]\n",
    "# voll_dict = {\n",
    "#     \"ss\": {\"ind_var_col\": \"res_time_yr\", \"model\": \"sigma_constant\", \"sigma\": 90}\n",
    "# }\n",
    "\n",
    "# # Set Vollenweider parameters for calibration\n",
    "# params = Parameters()\n",
    "# params.add(\"ss_sigma\", value=90, min=1, max=100, vary=True)\n",
    "\n",
    "# validate_input(model_pars, voll_dict, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89648b4-b966-4d6a-9758-7b0daac72a82",
   "metadata": {},
   "source": [
    "### 3.2. N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f677d7a-97ed-43c7-8584-b5d06033b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters of interest and default Vollenweider models (based on original literature data)\n",
    "# model_pars = [\"din\", \"ton\"]\n",
    "# voll_dict = {\n",
    "#     \"din\": {\"ind_var_col\": \"hyd_load_mpyr\", \"model\": \"sigma_from_depth\", \"s\": 6.0},\n",
    "#     \"ton\": {\"ind_var_col\": \"hyd_load_mpyr\", \"model\": \"sigma_from_depth\", \"s\": 1.4},\n",
    "# }\n",
    "\n",
    "# # Set Vollenweider parameters for calibration\n",
    "# params = Parameters()\n",
    "# params.add(\"din_s\", value=6.0, min=3, max=12, vary=True)\n",
    "# params.add(\"ton_s\", value=1.4, min=0.5, max=5, vary=True)\n",
    "\n",
    "# validate_input(model_pars, voll_dict, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff346e7-8f35-4d7c-be19-2f50bfb9dd21",
   "metadata": {},
   "source": [
    "### 3.3. P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fcb37-bac6-4afb-85fb-59ccafd96202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters of interest and default Vollenweider models (based on original literature data)\n",
    "# model_pars = [\"tdp\", \"tpp\"]\n",
    "# voll_dict = {\n",
    "#     \"tdp\": {\n",
    "#         \"ind_var_col\": \"res_time_yr\",\n",
    "#         \"model\": \"sigma_from_tau\",\n",
    "#         \"k\": 0.5,\n",
    "#         \"p\": 0.5,\n",
    "#     },\n",
    "#     \"tpp\": {\n",
    "#         \"ind_var_col\": \"res_time_yr\",\n",
    "#         \"model\": \"sigma_from_tau\",\n",
    "#         \"k\": 2,\n",
    "#         \"p\": 0.5,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # Set Vollenweider parameters for calibration\n",
    "# params = Parameters()\n",
    "# params.add(\"tdp_k\", value=0.5, min=0.1, max=4, vary=True)\n",
    "# params.add(\"tdp_p\", value=0.5, min=0.1, max=4, vary=True)\n",
    "# params.add(\"tpp_k\", value=2, min=0.1, max=4, vary=True)\n",
    "# params.add(\"tpp_p\", value=0.5, min=0.1, max=4, vary=True)\n",
    "\n",
    "# validate_input(model_pars, voll_dict, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4515b31-97d8-4e66-a67f-7b521088e738",
   "metadata": {},
   "source": [
    "### 3.4. TOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80be067-5e9e-44e0-b8fa-06e0219cc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters of interest and default Vollenweider models (based on original literature data)\n",
    "# model_pars = [\"toc\"]\n",
    "# voll_dict = {\n",
    "#     \"toc\": {\n",
    "#         \"ind_var_col\": \"res_time_yr\",\n",
    "#         \"model\": \"sigma_from_tau\",\n",
    "#         \"k\": 0.6,\n",
    "#         \"p\": 0.4,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Set Vollenweider parameters for calibration\n",
    "# params = Parameters()\n",
    "# params.add(\"toc_k\", value=0.6, min=0.1, max=2, vary=True)\n",
    "# params.add(\"toc_p\", value=0.4, min=0.1, max=2, vary=True)\n",
    "\n",
    "# validate_input(model_pars, voll_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b25b4a-d672-4e1b-b20a-24395a46346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = minimize(\n",
    "    residual,\n",
    "    params,\n",
    "    args=(st_yr, end_yr, model_pars, voll_dict, dtm_res),\n",
    "    nan_policy=\"omit\",\n",
    ")\n",
    "print(fit_report(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286c956-3ba5-4dd2-b2c7-2981a4c95679",
   "metadata": {},
   "source": [
    "## 4. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3516ba-fb30-4e8d-b033-d345b635aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with optimised parameters\n",
    "res_df = run_model(res.params, st_yr, end_yr, model_pars, voll_dict, dtm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef729a4c-1a6a-40d4-af44-95a302ec489b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sn.scatterplot(res_df, x=\"observed\", y=\"modelled\", hue=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4515e3-b207-4b36-9180-1f668d49a74e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "par_list = res_df[\"variable\"].unique().tolist()\n",
    "for idx, par in enumerate(par_list):\n",
    "    par_df = res_df.query(\"variable == @par\").copy()\n",
    "    r2 = r2_score(par_df[\"observed\"], par_df[\"modelled\"])\n",
    "    axes[idx].plot(par_df[\"observed\"], par_df[\"modelled\"], \"ro\")\n",
    "    axes[idx].plot(par_df[\"observed\"], par_df[\"observed\"], \"k-\", label=\"1:1 line\")\n",
    "    axes[idx].set_title(f\"{par} (R2={r2:.2f})\")\n",
    "    axes[idx].set_xlabel(\"Observed (tonnes)\")\n",
    "    axes[idx].set_ylabel(\"Modelled (tonnes)\")\n",
    "    # axes[idx].set_xscale('log')\n",
    "    # axes[idx].set_yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac21a5-3be9-4cf0-9bd2-e2ad77adf0aa",
   "metadata": {},
   "source": [
    "## 5. Results\n",
    "\n",
    "The notebooks in the `calibration` subfolder contain results for each parameter. In summary, for the optimised model:\n",
    "\n",
    " * For DIN, parameter `s` increases from 6 to 9\n",
    " * For TON, parameter `s` increases from 1.4 to 3\n",
    " * For TDP, parameter `k` changes from 0.5 to 0.2 and `p` changes from 0.5 to 0.6\n",
    " * For TPP, parameter `k` changes from 2 to 3 and `p` changes from 0.5 to 0.4\n",
    " * For TOC, parameter `k` changes from 0.6 to 0.4, but `p` remains unchanged\n",
    " * For SS, parameter `sigma` changes from 90 to 7\n",
    "\n",
    "**Not all of these changes can be justified**. For DIN, the improvement in performance is marginal, but does mean the model will give a better fit to independently measured data from MjÃ¸sa. For TON, TDP and TPP, the changes seem reasonable and are broadly within the ranges of uncertainty from the original literature analysis. For SS, changing `sigma` from 90 to 6 **cannot** be justified and seems to contradict the existing literature. I therefore believe TEOTIL3 is currently substantially underestimating inputs of SS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf93a6c-1f75-4cf6-b87a-cfb496c2d531",
   "metadata": {},
   "source": [
    "## 6. Proposed default retention parameters\n",
    "\n",
    "Based on available literature and calibration against Norwegian monitoring data, the following \"default\" equations are proposed for modelling retention and transmission in TEOTIL3. \n",
    "\n",
    "**Note:** These equations may be revised in future as more data become available.\n",
    "\n",
    "In all equations below, $\\tau$ is the lake water residence time (in years) and $H$ is the hydraulic load (in $m.year^{-1}$).\n",
    "\n",
    "### 6.1. P\n",
    "\n",
    " * **Transmission of TDP** will be modelled as \n",
    " \n",
    "$$\n",
    "T_{TDP} = \\frac{1}{1 + 0.2 \\tau ^{0.6}}\n",
    "$$\n",
    " \n",
    " * **Transmission of TPP** will be modelled as \n",
    " \n",
    "$$\n",
    "T_{TPP} = \\frac{1}{1 + 3 \\tau ^{0.4}}\n",
    "$$\n",
    " \n",
    " * To preserve conservation of mass, **transmission of TOTP** will be modelled as a weighted sum of the two functions above. However, the functions for TDP and TPP have been constructed such that typical retention for TOTP will broadly follow the well-established relationship\n",
    " \n",
    "$$\n",
    "T_{TOTP} = \\frac{1}{1 + \\tau ^{0.5}}\n",
    "$$\n",
    "\n",
    "### 6.2. N\n",
    "\n",
    " * **Transmission of DIN** will be modelled as \n",
    " \n",
    "$$T_{DIN} = \\frac{1}{1 + \\frac{8.0}{H}}$$\n",
    " \n",
    " * **Transmission of TON** will be modelled as \n",
    " \n",
    "$$T_{TON} = \\frac{1}{1 + \\frac{3.0}{H}}$$\n",
    "\n",
    " * To preserve conservation of mass, **transmission of TOTN** will be modelled as a weighted sum of the two functions above. However, the functions for DIN and TON have been constructed such that typical retention for TOTN will be broadly compatible with the relationship\n",
    " \n",
    "$$T_{TOTN} = \\frac{1}{1 + \\frac{6.0}{H}}$$\n",
    "\n",
    "### 6.3. SS\n",
    "\n",
    " * **Transmission of SS** will be modelled as\n",
    " \n",
    "$$T_{SS} = \\frac{1}{1 + 60 \\tau}$$\n",
    "\n",
    "### 6.4. TOC\n",
    "\n",
    " * **Transmission of TOC** will be modelled as\n",
    " \n",
    "$$T_{TOC} = \\frac{1}{1 + 0.4 \\tau ^{0.4}}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

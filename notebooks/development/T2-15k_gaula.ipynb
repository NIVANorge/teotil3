{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d04bbc-2110-4865-b519-e5f23391e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this and then restart the kernel at the start of each session to install\n",
    "# # 'teotil3' in development mode\n",
    "# !pip install -e /home/jovyan/projects/teotil3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b262bda5-93fb-4414-82ed-6565e9f62aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import teotil3 as teo\n",
    "from sqlalchemy import text\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff770e64-da0e-4361-8efd-d2e919b8ef1f",
   "metadata": {},
   "source": [
    "# Task 2.15: Testing, documentation and reporting\n",
    "\n",
    "## Part K: Gaula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e697291-5920-420c-9472-20e1d7e2d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to JupyterHub's PostGIS database\n",
    "eng = nivapy.da.connect_postgis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d313b-a55f-41a9-85df-285645b3c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "xl_path = r\"../../data/gaula_data.xlsx\"\n",
    "stn_df = pd.read_excel(xl_path, sheet_name=\"station\")\n",
    "wc_df = pd.read_excel(xl_path, sheet_name=\"chem\", decimal=\",\")\n",
    "wc_df[\"date\"] = pd.to_datetime(wc_df[\"date\"])\n",
    "\n",
    "print(\"Water chemsitry data:\")\n",
    "display(wc_df.head())\n",
    "\n",
    "print(\"Station details:\")\n",
    "display(stn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be051c73-aee0-4536-9ac3-196ff512abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure\n",
    "wc_df = wc_df.groupby([\"site_id\", \"parameter\", \"date\"]).mean()\n",
    "wc_df = wc_df.unstack(\"parameter\")\n",
    "wc_df.columns = [f\"{col}\" for col in wc_df.columns.get_level_values(1)]\n",
    "wc_df.reset_index(inplace=True)\n",
    "\n",
    "wc_df.rename(columns={\"TOTN\": \"TOTN_ug/l\", \"TOTP\": \"TOTP_ug/l\", \"TOC\":\"TOC_mg/l\"}, inplace=True)\n",
    "\n",
    "wc_df.dropna(how='any', inplace=True)\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c54568-6fc7-4118-a2bf-3972d4a2e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_df = wc_df.query(\"date >= '2013-01-01'\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "pars = ['TOTN_ug/l', 'TOTP_ug/l', \"TOC_mg/l\"]\n",
    "for idx, par in enumerate(pars):\n",
    "    par_df = wc_df[['date', par]].copy()\n",
    "    par_df.sort_values(\"date\", inplace=True)\n",
    "    axes[idx].plot(par_df[\"date\"], par_df[par], \"ko-\")\n",
    "    axes[idx].set_title(par)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94095d4b-6195-402f-82ea-adda8bda61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nve_stn_df = nivapy.da.get_nve_hydapi_stations()\n",
    "nve_id = stn_df['nve_station_id'].iloc[0]\n",
    "nve_stn_df = nve_stn_df.query(\"station_id == @nve_id\")\n",
    "nve_stn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b7874-78d4-49c3-bccb-299e0dbc7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive catchment boundaries for chem and Q stations\n",
    "stn_gdf = nivapy.spatial.derive_watershed_boundaries(\n",
    "    stn_df,\n",
    "    id_col=\"site_id\",\n",
    "    xcol=\"lon\",\n",
    "    ycol=\"lat\",\n",
    "    crs=\"epsg:4326\",\n",
    "    min_size_km2=5,\n",
    "    dem_res_m=40,\n",
    "    buffer_km=None,\n",
    "    temp_fold=None,\n",
    "    reproject=False,\n",
    ")\n",
    "stn_gdf[\"chem_area_km2\"] = stn_gdf.to_crs({\"proj\": \"cea\"}).geometry.area / 1e6\n",
    "\n",
    "nve_gdf = nivapy.spatial.derive_watershed_boundaries(\n",
    "    nve_stn_df,\n",
    "    id_col=\"station_id\",\n",
    "    xcol=\"longitude\",\n",
    "    ycol=\"latitude\",\n",
    "    crs=\"epsg:4326\",\n",
    "    min_size_km2=5,\n",
    "    dem_res_m=40,\n",
    "    buffer_km=None,\n",
    "    temp_fold=None,\n",
    "    reproject=False,\n",
    ")\n",
    "nve_gdf[\"q_area_km2\"] = nve_gdf.to_crs({\"proj\": \"cea\"}).geometry.area / 1e6\n",
    "nve_gdf[\"nve_station_id\"] = nve_gdf[\"station_id\"]\n",
    "\n",
    "# Join areas back to 'stn_df' and compare to NVE values for the Q stations (from HydAPI)\n",
    "stn_df = pd.merge(\n",
    "    stn_df,\n",
    "    stn_gdf[[\"site_id\", \"chem_area_km2\"]],\n",
    "    how=\"left\",\n",
    "    on=\"site_id\",\n",
    ")\n",
    "stn_df = pd.merge(\n",
    "    stn_df,\n",
    "    nve_gdf[[\"nve_station_id\", \"q_area_km2\"]],\n",
    "    how=\"left\",\n",
    "    on=\"nve_station_id\",\n",
    ")\n",
    "\n",
    "stn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa1374-58f1-4fc0-b679-715469d082e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate annual fluxes\n",
    "df_list = []\n",
    "par_list = ['TOTN_ug/l', 'TOTP_ug/l', \"TOC_mg/l\"]\n",
    "for idx, row in stn_df.iterrows():\n",
    "    vm_id = row[\"site_id\"]\n",
    "    nve_id = row[\"nve_station_id\"]\n",
    "    area_fac = row[\"chem_area_km2\"] / row[\"q_area_km2\"]\n",
    "\n",
    "    # Get chem data for station\n",
    "    chem_stn_df = wc_df.query(\"site_id == @vm_id\").copy()\n",
    "    chem_stn_df.set_index(\"date\", inplace=True)\n",
    "    chem_stn_df = chem_stn_df[par_list].resample(\"D\").mean().dropna()\n",
    "\n",
    "    # Get flow data for stations\n",
    "    q_stn_df = nivapy.da.query_nve_hydapi(\n",
    "        [nve_id], [1001], f\"2013-01-01\", f\"2022-12-31\", resolution=1440\n",
    "    )\n",
    "    q_stn_df = area_fac * q_stn_df.set_index(\"datetime\")[[\"value\"]].resample(\"D\").mean()\n",
    "    q_stn_df.index = q_stn_df.index.tz_localize(None)\n",
    "    q_stn_df.rename(columns={\"value\": \"flow_m3/s\"}, inplace=True)\n",
    "\n",
    "    # Calculate annual fluxes\n",
    "    flux_df = nivapy.stats.estimate_fluxes(\n",
    "        q_stn_df,\n",
    "        chem_stn_df,\n",
    "        base_freq=\"D\",\n",
    "        agg_freq=\"A\",\n",
    "        method=\"ospar_annual\",\n",
    "    )\n",
    "\n",
    "    # Convert kg to tonnes\n",
    "    flux_df = flux_df / 1000\n",
    "    flux_df.columns = [col.replace(\"kg\", \"tonnes\") for col in flux_df.columns]\n",
    "    flux_df[\"site_id\"] = vm_id\n",
    "    df_list.append(flux_df)\n",
    "flux_df = pd.concat(df_list, axis=\"rows\")\n",
    "flux_df = flux_df.reset_index()\n",
    "\n",
    "flux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e9bdc-6f3d-4c53-84d9-c37381312522",
   "metadata": {},
   "outputs": [],
   "source": [
    "nve_data_year = 2023\n",
    "st_yr, end_yr = 2013, 2022\n",
    "out_csv_fold = r\"/home/jovyan/shared/common/teotil3/annual_input_data\"\n",
    "eval_fold = r\"/home/jovyan/shared/common/teotil3/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49c347-ed3e-4016-b5e5-c070407d1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix) :]\n",
    "    return text\n",
    "    \n",
    "# Read saved data for speed\n",
    "mod_csv = os.path.join(\n",
    "    eval_fold, f\"teo3_results_nve{nve_data_year}_{st_yr}-{end_yr}.csv\"\n",
    ")\n",
    "mod_df = pd.read_csv(mod_csv)\n",
    "   \n",
    "# Tidy modelled data for comparison\n",
    "cols = [col for col in mod_df.columns if col.startswith(\"accum_\")]\n",
    "mod_df = mod_df[[\"regine\", \"year\"] + cols].copy()\n",
    "cols = [remove_prefix(col, \"accum_\") for col in cols]\n",
    "mod_df.columns = [\"regine\", \"year\"] + cols\n",
    "for col in cols:\n",
    "    if col.endswith(\"_kg\"):\n",
    "        mod_df[col[:-3] + \"_tonnes\"] = mod_df[col] / 1000\n",
    "    del mod_df[col]\n",
    "\n",
    "reg_id = stn_df['regine'].iloc[0]\n",
    "mod_df = mod_df.query(\"regine in @reg_id\")\n",
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe70bb9-3a44-4590-87e1-813b8154983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "comp_df = pd.merge(flux_df, mod_df, how=\"left\", on=\"year\")\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abbbb7-8dc7-42ba-94c1-8e1bb7e60671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: single parameter per river\n",
    "pars = [\"TOTN\", \"TOTP\", \"TOC\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,3))\n",
    "\n",
    "for idx, par in enumerate(pars):\n",
    "    par_cols = [\n",
    "        col\n",
    "        for col in comp_df.columns\n",
    "        if par.lower() in (i.lower() for i in col.split(\"_\"))\n",
    "    ]\n",
    "\n",
    "    comp_par_df = comp_df.set_index(\"year\")[par_cols]\n",
    "\n",
    "    comp_par_df.drop(columns=[f\"{par}_tonnes\"]).plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        ax=axes[idx],\n",
    "        legend=False,\n",
    "        cmap=\"tab10\",\n",
    "    )\n",
    "\n",
    "    axes[idx].plot(\n",
    "        comp_par_df.index - comp_par_df.index.min(),\n",
    "        comp_par_df[f\"{par}_tonnes\"],\n",
    "        marker=\"o\",\n",
    "        color=\"red\",\n",
    "        label=\"Observed\",\n",
    "    )\n",
    "    axes[idx].set_title(par)\n",
    "    axes[idx].set_ylabel(f\"{par} (tonnes)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"lower center\", bbox_to_anchor=(0.5, -0.4), ncol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

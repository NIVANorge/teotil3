{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca53e063-0c0c-4908-9fd6-e6bf0415ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dfd768-9b52-497f-b52e-7f5f632c702e",
   "metadata": {},
   "source": [
    "# Explore geology as covariate\n",
    "\n",
    "According to Bogen (1996), SS in the Atna at Li Bru (`2.479.0`) comes from a small area of Pleistocene sediments (~30 km2), with the rest of the catchment (>110 km2) generating essentially nothing. This notebook uses geological map data from NGU to summarise geology in this catchment. \n",
    "\n",
    "Unfortunately, the NGU bedrock dataset does not show any \"løsmasse\" in this area. By contrast, the Løsmasse kart shows løsmasse everywhere, and it is not clear how to estimate anything comparable to Bogen's 30 km2 of Pleistocene sediments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf57f1c-61eb-4e73-9efb-67493861c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyogrio/raw.py:194: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n",
      "  result = ogr_read(\n",
      "/opt/conda/lib/python3.11/site-packages/pyogrio/geopandas.py:49: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  res = pd.to_datetime(ser, **datetime_kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/pyogrio/geopandas.py:49: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  res = pd.to_datetime(ser, **datetime_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojecting to equal area...\n",
      "Intersecting polygons...\n",
      "Aggregating...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>a_304.0_km2</th>\n",
       "      <th>a_306.0_km2</th>\n",
       "      <th>a_321.0_km2</th>\n",
       "      <th>a_412.0_km2</th>\n",
       "      <th>a_424.0_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.479.0</td>\n",
       "      <td>112.909596</td>\n",
       "      <td>24.105067</td>\n",
       "      <td>0.063953</td>\n",
       "      <td>16.464968</td>\n",
       "      <td>2.940982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id  a_304.0_km2  a_306.0_km2  a_321.0_km2  a_412.0_km2  a_424.0_km2\n",
       "0    2.479.0   112.909596    24.105067     0.063953    16.464968     2.940982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = r\"/home/jovyan/shared/common/teotil3/nve_ss_data\"\n",
    "cat_gdf = gpd.read_file(os.path.join(dir_path, \"filtered_catchments.gpkg\")).query(\"station_id == '2.479.0'\")\n",
    "geo_gdf = gpd.read_file(os.path.join(dir_path, \"BerggrunnN50.gdb\"), layer=\"BergartFlate_N50\")\n",
    "\n",
    "print(\"Reprojecting to equal area...\")\n",
    "cat_gdf_cea = cat_gdf.to_crs({\"proj\": \"cea\"})\n",
    "geo_gdf_cea = geo_gdf.to_crs({\"proj\": \"cea\"})\n",
    "cat_gdf_cea.sindex\n",
    "geo_gdf_cea.sindex\n",
    "\n",
    "print(\"Intersecting polygons...\")\n",
    "int_gdf = gpd.overlay(\n",
    "    cat_gdf_cea, geo_gdf_cea[['hovedbergart', 'geometry']], how=\"intersection\", keep_geom_type=True\n",
    ")\n",
    "int_gdf[\"area_km2\"] = int_gdf[\"geometry\"].area / 1e6\n",
    "\n",
    "print(\"Aggregating...\")\n",
    "lc_df = int_gdf.groupby([\"station_id\", \"hovedbergart\"]).sum(numeric_only=True)[\"area_km2\"]\n",
    "lc_df = lc_df.unstack(\"hovedbergart\")\n",
    "lc_df.columns = [f\"a_{i}_km2\" for i in lc_df.columns]\n",
    "lc_df.reset_index(inplace=True)\n",
    "lc_df.columns.name = \"\"\n",
    "\n",
    "# cat_gdf = pd.merge(cat_gdf, lc_df, on=\"station_id\", how=\"left\")\n",
    "# cat_gdf['a_løsmasser_km2'] = cat_gdf['a_løsmasser_km2'].fillna(0)\n",
    "lc_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

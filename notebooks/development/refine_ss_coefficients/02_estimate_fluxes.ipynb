{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506d9b6-1f75-4d71-b0b4-455d4045307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d701f39-48a9-40f8-96a4-a2d452c3cc45",
   "metadata": {},
   "source": [
    "# Improving suspended sediment coefficients in TEOTIL3\n",
    "\n",
    "## Notebook 02: Estimate SS fluxes\n",
    "\n",
    "This notebook uses NVE's GTS API to estimate daily flows for each catchment identified in notebook 01. Annual SS fluxes are then calculated using the OSPAR ratio estimator.\n",
    "\n",
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e2d8d-cf26-4a20-adf6-4178b30fe8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from notebook 01\n",
    "dir_path = r\"/home/jovyan/shared/common/teotil3/nve_ss_data\"\n",
    "cat_gdf = gpd.read_file(os.path.join(dir_path, \"filtered_catchments.gpkg\"))\n",
    "df = pd.read_excel(os.path.join(dir_path, \"filtered_data.xlsx\"), sheet_name=\"data\")\n",
    "df = df.rename(columns={\"SS_mgpl\": \"SS_mg/l\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b737d-c465-4462-84b2-dff10561ad6a",
   "metadata": {},
   "source": [
    "## 2. Estimate daily flows using GTS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb1e38-cbed-4040-a096-ce840055b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get flow data from the GTS API\n",
    "# Loop over catchments of interest. GTS API occasionally times-out, so the code\n",
    "# below includes a hacky solution to retry up to 'n_retries' times when this occurs.\n",
    "# TO DO: Update nivapy.da.get_nve_gts_api_aggregated_time_series to properly handle\n",
    "# timeout errors, then streamline this code.\n",
    "n_retries = 10\n",
    "df_list = []\n",
    "for idx in range(len(cat_gdf)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing {idx+1}/{len(cat_gdf)}\")\n",
    "    retry_count = 0\n",
    "    while retry_count < n_retries:\n",
    "        try:\n",
    "            # Get start and end year for this site\n",
    "            stn_id = cat_gdf.iloc[idx][\"station_id\"]\n",
    "            stn_chem_df = df.query(\"station_id == @stn_id\").copy()\n",
    "            stn_chem_df[\"year\"] = stn_chem_df[\"date\"].dt.year\n",
    "            st_yr = stn_chem_df[\"year\"].min()\n",
    "            end_yr = stn_chem_df[\"year\"].max()\n",
    "\n",
    "            # Get data from GTS API\n",
    "            q_df = nivapy.da.get_nve_gts_api_aggregated_time_series(\n",
    "                cat_gdf.iloc[[idx]],\n",
    "                [\"gwb_q\"],\n",
    "                f\"{st_yr}-01-01\",\n",
    "                f\"{end_yr}-12-31\",\n",
    "                id_col=\"station_id\",\n",
    "            )\n",
    "            break\n",
    "        except ValueError:\n",
    "            # No data for catchment. Move to next iteration\n",
    "            q_df = None\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # Probably a TimeoutError. Retry\n",
    "            retry_count += 1\n",
    "            if retry_count >= n_retries:\n",
    "                q_df = None\n",
    "                break\n",
    "\n",
    "    if q_df is None:\n",
    "        continue\n",
    "\n",
    "    cat_area = cat_gdf[\"area_km2\"].iloc[idx]\n",
    "    q_df[\"flow_m3/s\"] = 1e6 * q_df[\"value_mean\"] * cat_area / (1000 * 60 * 60 * 24)\n",
    "    q_df = q_df[[\"datetime\", \"flow_m3/s\"]]\n",
    "    q_df.columns = [\"date\", \"flow_m3/s\"]\n",
    "\n",
    "    # Resample to output frequency\n",
    "    q_df = q_df.set_index(\"date\").resample(\"D\").mean().reset_index()\n",
    "    q_df[\"station_id\"] = stn_id\n",
    "    q_df = q_df[[\"station_id\", \"date\", \"flow_m3/s\"]]\n",
    "\n",
    "    df_list.append(q_df)\n",
    "\n",
    "q_df = pd.concat(df_list, axis=\"rows\")\n",
    "\n",
    "# Save\n",
    "flow_csv_path = os.path.join(dir_path, \"flows_gts-api.csv\")\n",
    "q_df.to_csv(flow_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a3eac-2004-40c9-a5c0-8e339e8c40e0",
   "metadata": {},
   "source": [
    "## 2. Calculate SS loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6faf4-83cd-4cbf-a557-b9809296ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_list = q_df[\"station_id\"].unique().tolist()\n",
    "df = df.query(\"station_id in @stn_list\")\n",
    "cat_gdf = cat_gdf.query(\"station_id in @stn_list\")\n",
    "\n",
    "df_list = []\n",
    "for stn_id in stn_list:\n",
    "    stn_chem_df = df.query(\"station_id == @stn_id\").set_index(\"date\")\n",
    "    stn_q_df = q_df.query(\"station_id == @stn_id\").set_index(\"date\")\n",
    "    del stn_chem_df[\"station_id\"], stn_q_df[\"station_id\"]\n",
    "\n",
    "    stn_flux_df = nivapy.stats.estimate_fluxes(\n",
    "        stn_q_df,\n",
    "        stn_chem_df,\n",
    "        base_freq=\"D\",\n",
    "        agg_freq=\"A\",\n",
    "        method=\"ospar_annual\",\n",
    "        st_date=None,\n",
    "        end_date=None,\n",
    "        plot_fold=None,\n",
    "    )\n",
    "    stn_flux_df[\"station_id\"] = stn_id\n",
    "    stn_flux_df = stn_flux_df.query(\"SS_kg > 0\").reset_index()\n",
    "    stn_flux_df = stn_flux_df[[\"station_id\", \"year\", \"SS_kg\"]]\n",
    "    df_list.append(stn_flux_df)\n",
    "\n",
    "flux_df = pd.concat(df_list, axis=\"rows\")\n",
    "\n",
    "# Save\n",
    "flux_csv_path = os.path.join(dir_path, \"ss_fluxes.csv\")\n",
    "flux_df.to_csv(flux_csv_path, index=False)\n",
    "\n",
    "flux_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
